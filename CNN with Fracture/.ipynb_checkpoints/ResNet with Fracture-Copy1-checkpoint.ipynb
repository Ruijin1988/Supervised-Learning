{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpy7aymk/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpy7aymk/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: Quadro K2000 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == MNIST ==\n",
      "X_train shape: (80L, 1L, 144L, 144L)\n",
      "80 train samples\n",
      "20 test samples\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 144, 144))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 146, 146))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 148, 148))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 150, 150))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 152, 152))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 24 ---> num feature maps on out: 48\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (48, 76, 76))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (48, 78, 78))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (48, 80, 80))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 48 ---> num feature maps on out: 64\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (64, 40, 40))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 64 ---> num feature maps on out: 48\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (48, 42, 42))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 48 ---> num feature maps on out: 64\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (64, 44, 44))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 64 ---> num feature maps on out: 96\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (96, 22, 22))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (96, 24, 24))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (96, 26, 26))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (96, 28, 28))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 96 ---> num feature maps on out: 128\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (128, 14, 14))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (128, 16, 16))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (128, 18, 18))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (128, 20, 20))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 128 ---> num feature maps on out: 192\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (192, 10, 10))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (192, 12, 12))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (192, 14, 14))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (192, 16, 16))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (192, 18, 18))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 192 ---> num feature maps on out: 384\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (384, 9, 9))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (384, 9, 9))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (384, 9, 9))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "Average pooling, from (9,9) to (1,1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3235ed50cdbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_residual_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_mnist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_mnist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;31m#     # autosave best Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, sample_weight_mode, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m                            \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m                            \u001b[0msample_weight_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m                            **kwargs)\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[0mloss_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_weights_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             output_loss = weighted_loss(y_true, y_pred,\n\u001b[1;32m--> 622\u001b[1;33m                                         sample_weight, mask)\n\u001b[0m\u001b[0;32m    623\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mweighted\u001b[1;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mweighted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;31m# Cast the mask to floatX to avoid float64 upcasting in theano\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-3235ed50cdbb>\u001b[0m in \u001b[0;36mexp_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mexp_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.setrecursionlimit(99999)\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import ZeroPadding2D, AveragePooling2D, Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import residual_blocks\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "nb_classes = 1\n",
    "nb_epoch = 200\n",
    "\n",
    "def compute_padding_length(length_before, stride, length_conv):\n",
    "    ''' Assumption: you want the subsampled result has a length of floor(original_length/stride).\n",
    "    '''\n",
    "    N = length_before\n",
    "    F = length_conv\n",
    "    S = stride\n",
    "    if S == F:\n",
    "        return 0\n",
    "    if S == 1:\n",
    "        return (F-1)/2\n",
    "    for P in range(S):\n",
    "        if (N-F+2*P)/S + 1 == N/S:\n",
    "            return P\n",
    "    return 0\n",
    "\n",
    "def design_for_residual_blocks(num_channel_input=1):\n",
    "    ''''''\n",
    "    model = Sequential() # it's a CONTAINER, not MODEL\n",
    "    # set numbers\n",
    "#     num_big_blocks = 6\n",
    "#     image_patch_sizes = [[6,6],[6,6],[9,9],[9,9],[9,9],[9,9]]\n",
    "#     pool_sizes = [(2,2)]*num_big_blocks\n",
    "#     n_features = [24, 24, 40, 40, 288, 288]\n",
    "#     n_features_next = [24, 40, 40, 288, 288,288]\n",
    "#     height_input = 144\n",
    "#     width_input = 144\n",
    "    num_big_blocks = 21\n",
    "    image_patch_sizes = [[3,3]]*num_big_blocks\n",
    "    pool_sizes = [(2,2)]*num_big_blocks\n",
    "    n_features =      [24,24,24,24,48,48,48,64,96,96,96, 128,128,128,192,192,192,192,384,384,384]\n",
    "    n_features_next = [24,24,24,48,48,64,48,96,96,96,128,128,128,192,192,192,192,384,384,384,384]\n",
    "    height_input = 144\n",
    "    width_input = 144\n",
    "    \n",
    "    for conv_idx in range(num_big_blocks):    \n",
    "        n_feat_here = n_features[conv_idx]\n",
    "        # residual block 0\n",
    "        model.add(residual_blocks.building_residual_block(  (num_channel_input, height_input, width_input),\n",
    "                                                            n_feat_here,\n",
    "                                                            kernel_sizes=image_patch_sizes[conv_idx]\n",
    "                                                            ))\n",
    "\n",
    "        # residual block 1 (you can add it as you want (and your resources allow..))\n",
    "        if False:\n",
    "            model.add(residual_blocks.building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                                n_feat_here,\n",
    "                                                                kernel_sizes=image_patch_sizes[conv_idx]\n",
    "                                                                ))\n",
    "        \n",
    "        # the last residual block N-1\n",
    "        # the last one : pad zeros, subsamples, and increase #channels\n",
    "        pad_height = compute_padding_length(height_input, pool_sizes[conv_idx][0], image_patch_sizes[conv_idx][0])\n",
    "        pad_width = compute_padding_length(width_input, pool_sizes[conv_idx][1], image_patch_sizes[conv_idx][1])\n",
    "\n",
    "        model.add(ZeroPadding2D(padding=(pad_height,pad_width))) \n",
    "        height_input += 2*pad_height\n",
    "        width_input += 2*pad_width\n",
    "        n_feat_next = n_features_next[conv_idx]\n",
    "        if n_features[conv_idx]!=n_features_next[conv_idx]:\n",
    "            model.add(residual_blocks.building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                                n_feat_next,\n",
    "                                                                kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                                is_subsample=True,\n",
    "                                                                subsample=pool_sizes[conv_idx]\n",
    "                                                                ))\n",
    "\n",
    "        height_input, width_input = model.output_shape[2:]\n",
    "        # width_input  = int(width_input/pool_sizes[conv_idx][1])\n",
    "        num_channel_input = n_feat_next\n",
    "\n",
    "    # Add average pooling at the end:\n",
    "    print('Average pooling, from (%d,%d) to (1,1)' % (height_input, width_input))\n",
    "    model.add(AveragePooling2D(pool_size=(height_input, width_input)))\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_residual_model(is_mnist=True, img_channels=1, img_rows=144, img_cols=144):\n",
    "    model = keras.models.Sequential()\n",
    "    first_layer_channel = 24\n",
    "    if is_mnist: # size to be changed to 32,32\n",
    "        model.add(ZeroPadding2D((0,0), input_shape=(img_channels, img_rows, img_cols))) # resize (28,28)-->(32,32)\n",
    "        # the first conv \n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same'))\n",
    "    else:\n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same', input_shape=(img_channels, img_rows, img_cols)))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    # [residual-based Conv layers]\n",
    "    residual_blocks = design_for_residual_blocks(num_channel_input=first_layer_channel)\n",
    "    model.add(residual_blocks)\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    # [Classifier]    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('linear'))\n",
    "    # [END]\n",
    "    return model\n",
    "\n",
    "def exp_error(y_true, y_pred):\n",
    "    return K.mean(K.square(np.exp(y_pred) - np.exp(y_true)))\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    \n",
    "    is_mnist = True\n",
    "    is_cifar10 = not is_mnist\n",
    "    \n",
    "    if is_mnist:\n",
    "        import scipy.io as sio\n",
    "        import numpy as np\n",
    "        img_rows, img_cols = 144, 144\n",
    "        img_channels = 1\n",
    "        WB=sio.loadmat('WB_small.mat')['WB_small'].T\n",
    "        Y_data=sio.loadmat('true.mat')['skt']\n",
    "        Y_data=(Y_data-min(Y_data))/(max(Y_data)-min(Y_data))\n",
    "        X_data=np.reshape(WB,(100,1,img_rows,img_cols))\n",
    "        X_train=X_data[0:80];X_test=X_data[80:100]\n",
    "        Y_train=Y_data[0:80];Y_test=Y_data[80:100]\n",
    "        print(' == MNIST ==')\n",
    "#         (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#         img_rows, img_cols = 28, 28\n",
    "#         img_channels = 1\n",
    "#         print(' == MNIST ==')\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    # X_train /= 255\n",
    "    # X_test /= 255\n",
    "    #X_train = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "    #X_test = (X_test - np.mean(X_test))/np.std(X_test)\n",
    "    \n",
    "#     X_train = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "#     X_test = (X_test - np.mean(X_test))/np.std(X_test)\n",
    "#     Y_train = y_train\n",
    "#     Y_test = y_test\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    model = get_residual_model(is_mnist=is_mnist, img_channels=img_channels, img_rows=img_rows, img_cols=img_cols)\n",
    "\n",
    "    model.compile(loss=exp_error, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#     # autosave best Model\n",
    "#     best_model_file = \"./my_model_weights.h5\"\n",
    "#     best_model = ModelCheckpoint(best_model_file, verbose=1, save_best_only=True)\n",
    "    \n",
    "#     model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "#               verbose=1, validation_data=(X_test, Y_test))#, callbacks=[best_model])\n",
    "#     score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "You must compile your model before using it.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ff29a69e1a79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1045\u001b[0m                                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m                                                                            batch_size=batch_size)\n\u001b[1;32m-> 1047\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m             \u001b[0mval_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36m_make_test_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test_function'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'You must compile your model before using it.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: You must compile your model before using it."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=500,verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=500,verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0598288 ],\n",
       "       [-0.22975894],\n",
       "       [ 0.02204274],\n",
       "       [ 0.16350582],\n",
       "       [-0.26330754],\n",
       "       [-0.18016099],\n",
       "       [-0.46485456],\n",
       "       [-0.32365561],\n",
       "       [ 0.09812948],\n",
       "       [ 0.10863168],\n",
       "       [-0.24898307],\n",
       "       [-0.01799552],\n",
       "       [ 0.07780188],\n",
       "       [-0.09783778],\n",
       "       [-0.14135144],\n",
       "       [ 0.2093093 ],\n",
       "       [-0.05261862],\n",
       "       [ 0.20715234],\n",
       "       [ 0.10180938],\n",
       "       [ 0.39897717]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test-model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_residual_model(is_mnist=is_mnist, img_channels=img_channels, img_rows=img_rows, img_cols=img_cols)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# autosave best Model\n",
    "best_model_file = \"./my_model_weights.h5\"\n",
    "best_model = ModelCheckpoint(best_model_file, verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))#, callbacks=[best_model])\n",
    "score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14737975597381592, 0.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == MNIST ==\n",
      "X_train shape: (80L, 1L, 144L, 144L)\n",
      "80 train samples\n",
      "20 test samples\n",
      "   - New residual block with\n",
      "('      input shape:', (128, 148, 148))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (128, 150, 150))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 128 ---> num feature maps on out: 256\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (256, 74, 74))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (256, 76, 76))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 256 ---> num feature maps on out: 512\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 37, 37))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 37, 37))\n",
      "('      kernel size:', [3, 3])\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 18, 18))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 20, 20))\n",
      "('      kernel size:', [3, 3])\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 9, 9))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 512 ---> num feature maps on out: 1024\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (1024, 9, 9))\n",
      "('      kernel size:', [3, 3])\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "Average pooling, from (4,4) to (1,1)\n"
     ]
    }
   ],
   "source": [
    "'''Example of using residual_blocks.py by Keunwoo Choi (keunwoo.choi@qmul.ac.uk), on Keras 0.3.2\n",
    "It's copy-and-pasted from the code I am using, so it wouldn't run.\n",
    "Just take a look to understand how to use residual blocks. \n",
    "\n",
    "The whole structure is...\n",
    "\n",
    "   -------Residual Model (keras.models.Sequential())-------\n",
    "   |                                                      |\n",
    "   |     ---- Residual blocks ------------------------|   |\n",
    "   |     |    (keras.layers.containers.Sequential())  |   |\n",
    "   |     |                                            |   |\n",
    "   |     |     -- Many Residual blocks ------------   |   |\n",
    "   |     |     | (keras.layers.containers.Graph())|   |   |\n",
    "   |     |     |                                  |   |   |\n",
    "   |     |     |__________________________________|   |   |\n",
    "   |     |____________________________________________|   |\n",
    "   |                                                      |\n",
    "   |______________________________________________________|\n",
    "\n",
    "'''\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.setrecursionlimit(99999)\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import ZeroPadding2D, AveragePooling2D, Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import residual_blocks\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "nb_classes = 1\n",
    "nb_epoch = 20\n",
    "\n",
    "def compute_padding_length(length_before, stride, length_conv):\n",
    "    ''' Assumption: you want the subsampled result has a length of floor(original_length/stride).\n",
    "    '''\n",
    "    N = length_before\n",
    "    F = length_conv\n",
    "    S = stride\n",
    "    if S == F:\n",
    "        return 0\n",
    "    if S == 1:\n",
    "        return (F-1)/2\n",
    "    for P in range(S):\n",
    "        if (N-F+2*P)/S + 1 == N/S:\n",
    "            return P\n",
    "    return None\n",
    "\n",
    "def design_for_residual_blocks(num_channel_input=1):\n",
    "    ''''''\n",
    "    model = Sequential() # it's a CONTAINER, not MODEL\n",
    "    # set numbers\n",
    "    num_big_blocks = 5\n",
    "    image_patch_sizes = [[3,3]]*num_big_blocks\n",
    "    pool_sizes = [(2,2)]*num_big_blocks\n",
    "    n_features =      [128, 256, 512, 512, 1024]\n",
    "    n_features_next = [256, 512, 512, 512, 1024]\n",
    "    height_input = 148\n",
    "    width_input = 148\n",
    "    for conv_idx in range(num_big_blocks):    \n",
    "        n_feat_here = n_features[conv_idx]\n",
    "        # residual block 0\n",
    "        model.add(residual_blocks.building_residual_block(  (num_channel_input, height_input, width_input),\n",
    "                                                            n_feat_here,\n",
    "                                                            kernel_sizes=image_patch_sizes[conv_idx]\n",
    "                                                            ))\n",
    "\n",
    "        # residual block 1 (you can add it as you want (and your resources allow..))\n",
    "        if False:\n",
    "            model.add(residual_blocks.building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                                n_feat_here,\n",
    "                                                                kernel_sizes=image_patch_sizes[conv_idx]\n",
    "                                                                ))\n",
    "        \n",
    "        # the last residual block N-1\n",
    "        # the last one : pad zeros, subsamples, and increase #channels\n",
    "        pad_height = compute_padding_length(height_input, pool_sizes[conv_idx][0], image_patch_sizes[conv_idx][0])\n",
    "        pad_width = compute_padding_length(width_input, pool_sizes[conv_idx][1], image_patch_sizes[conv_idx][1])\n",
    "        model.add(ZeroPadding2D(padding=(pad_height,pad_width))) \n",
    "        height_input += 2*pad_height\n",
    "        width_input += 2*pad_width\n",
    "        n_feat_next = n_features_next[conv_idx]\n",
    "        model.add(residual_blocks.building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                            n_feat_next,\n",
    "                                                            kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                            is_subsample=True,\n",
    "                                                            subsample=pool_sizes[conv_idx]\n",
    "                                                            ))\n",
    "\n",
    "        height_input, width_input = model.output_shape[2:]\n",
    "        # width_input  = int(width_input/pool_sizes[conv_idx][1])\n",
    "        num_channel_input = n_feat_next\n",
    "\n",
    "    # Add average pooling at the end:\n",
    "    print('Average pooling, from (%d,%d) to (1,1)' % (height_input, width_input))\n",
    "    model.add(AveragePooling2D(pool_size=(height_input, width_input)))\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_residual_model(is_mnist=True, img_channels=1, img_rows=28, img_cols=28):\n",
    "    model = keras.models.Sequential()\n",
    "    first_layer_channel = 128\n",
    "    if is_mnist: # size to be changed to 32,32\n",
    "        model.add(ZeroPadding2D((2,2), input_shape=(img_channels, img_rows, img_cols))) # resize (28,28)-->(32,32)\n",
    "        # the first conv \n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same'))\n",
    "    else:\n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same', input_shape=(img_channels, img_rows, img_cols)))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    # [residual-based Conv layers]\n",
    "    residual_blocks = design_for_residual_blocks(num_channel_input=first_layer_channel)\n",
    "    model.add(residual_blocks)\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    # [Classifier]    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # [END]\n",
    "    return model\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    is_mnist = True\n",
    "    is_cifar10 = not is_mnist\n",
    "\n",
    "    if is_mnist:\n",
    "        import scipy.io as sio\n",
    "        import numpy as np\n",
    "\n",
    "        img_rows, img_cols = 144, 144\n",
    "        img_channels = 1\n",
    "        WB = sio.loadmat('WB_small.mat')['WB_small']\n",
    "        Y_data = sio.loadmat('true.mat')['skt']\n",
    "        Y_data = (Y_data - min(Y_data)) / (max(Y_data) - min(Y_data))\n",
    "        X_data = np.reshape(WB, (100, 1, img_rows, img_cols))\n",
    "        X_train = X_data[0:80];\n",
    "        X_test = X_data[80:100]\n",
    "        Y_train = Y_data[0:80];\n",
    "        Y_test = Y_data[80:100]\n",
    "        print(' == MNIST ==')\n",
    "    else:\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "        img_rows, img_cols = 32, 32\n",
    "        img_channels = 3\n",
    "        print(' == CIFAR10 ==')\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    # X_train /= 255\n",
    "    # X_test /= 255\n",
    "    # X_train = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "    # X_test = (X_test - np.mean(X_test))/np.std(X_test)\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    model = get_residual_model(is_mnist=is_mnist, img_channels=img_channels, img_rows=img_rows, img_cols=img_cols)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # # autosave best Model\n",
    "    # best_model_file = \"./my_model_weights.h5\"\n",
    "    # best_model = ModelCheckpoint(best_model_file, verbose=1, save_best_only=True)\n",
    "    #\n",
    "#     model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_test, Y_test))#, callbacks=[best_model])\n",
    "    # score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "    # print('Test score:', score[0])\n",
    "    # print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 1, 148, 148)   0           zeropadding2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 128, 148, 148) 1280        zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 128, 148, 148) 0           convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)        (None, 1024, 1, 1)    73990912    activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_34 (BatchNorma(None, 1024, 1, 1)    2048        sequential_4[1][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 1024, 1, 1)    0           batchnormalization_34[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1024)          0           activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             1025        flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 1)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 73995265\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == MNIST ==\n",
      "X_train shape: (80L, 1L, 144L, 144L)\n",
      "80 train samples\n",
      "20 test samples\n",
      "   - New residual block with\n",
      "('      input shape:', (128, 148, 148))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (128, 150, 150))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 128 ---> num feature maps on out: 256\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (256, 74, 74))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (256, 76, 76))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 256 ---> num feature maps on out: 512\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 37, 37))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 37, 37))\n",
      "('      kernel size:', [3, 3])\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 18, 18))\n",
      "('      kernel size:', [3, 3])\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 20, 20))\n",
      "('      kernel size:', [3, 3])\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (512, 9, 9))\n",
      "('      kernel size:', [3, 3])\n",
      "      - Input channels: 512 ---> num feature maps on out: 1024\n",
      "        -- model was built.\n",
      "   - New residual block with\n",
      "('      input shape:', (1024, 9, 9))\n",
      "('      kernel size:', [3, 3])\n",
      "('      - with subsample:', (2, 2))\n",
      "        -- model was built.\n",
      "Average pooling, from (4,4) to (1,1)\n"
     ]
    }
   ],
   "source": [
    "'''Example of using residual_blocks.py by Keunwoo Choi (keunwoo.choi@qmul.ac.uk), on Keras 0.3.2\n",
    "It's copy-and-pasted from the code I am using, so it wouldn't run.\n",
    "Just take a look to understand how to use residual blocks. \n",
    "\n",
    "The whole structure is...\n",
    "\n",
    "   -------Residual Model (keras.models.Sequential())-------\n",
    "   |                                                      |\n",
    "   |     ---- Residual blocks ------------------------|   |\n",
    "   |     |    (keras.layers.containers.Sequential())  |   |\n",
    "   |     |                                            |   |\n",
    "   |     |     -- Many Residual blocks ------------   |   |\n",
    "   |     |     | (keras.layers.containers.Graph())|   |   |\n",
    "   |     |     |                                  |   |   |\n",
    "   |     |     |__________________________________|   |   |\n",
    "   |     |____________________________________________|   |\n",
    "   |                                                      |\n",
    "   |______________________________________________________|\n",
    "\n",
    "'''\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.setrecursionlimit(99999)\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import ZeroPadding2D, AveragePooling2D, Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import residual_blocks\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "nb_classes = 1\n",
    "nb_epoch = 20\n",
    "\n",
    "def compute_padding_length(length_before, stride, length_conv):\n",
    "    ''' Assumption: you want the subsampled result has a length of floor(original_length/stride).\n",
    "    '''\n",
    "    N = length_before\n",
    "    F = length_conv\n",
    "    S = stride\n",
    "    if S == F:\n",
    "        return 0\n",
    "    if S == 1:\n",
    "        return (F-1)/2\n",
    "    for P in range(S):\n",
    "        if (N-F+2*P)/S + 1 == N/S:\n",
    "            return P\n",
    "    return None\n",
    "\n",
    "def design_for_residual_blocks(num_channel_input=1):\n",
    "    ''''''\n",
    "    model = Sequential() # it's a CONTAINER, not MODEL\n",
    "    # set numbers\n",
    "    num_big_blocks = 5\n",
    "    image_patch_sizes = [[3,3]]*num_big_blocks\n",
    "    pool_sizes = [(2,2)]*num_big_blocks\n",
    "    n_features =      [128, 256, 512, 512, 1024]\n",
    "    n_features_next = [256, 512, 512, 512, 1024]\n",
    "    height_input = 148\n",
    "    width_input = 148\n",
    "    for conv_idx in range(num_big_blocks):    \n",
    "        n_feat_here = n_features[conv_idx]\n",
    "        # residual block 0\n",
    "        model.add(residual_blocks.building_residual_block(  (num_channel_input, height_input, width_input),\n",
    "                                                            n_feat_here,\n",
    "                                                            kernel_sizes=image_patch_sizes[conv_idx]\n",
    "                                                            ))\n",
    "\n",
    "        # residual block 1 (you can add it as you want (and your resources allow..))\n",
    "        if False:\n",
    "            model.add(residual_blocks.building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                                n_feat_here,\n",
    "                                                                kernel_sizes=image_patch_sizes[conv_idx]\n",
    "                                                                ))\n",
    "        \n",
    "        # the last residual block N-1\n",
    "        # the last one : pad zeros, subsamples, and increase #channels\n",
    "        pad_height = compute_padding_length(height_input, pool_sizes[conv_idx][0], image_patch_sizes[conv_idx][0])\n",
    "        pad_width = compute_padding_length(width_input, pool_sizes[conv_idx][1], image_patch_sizes[conv_idx][1])\n",
    "        model.add(ZeroPadding2D(padding=(pad_height,pad_width))) \n",
    "        height_input += 2*pad_height\n",
    "        width_input += 2*pad_width\n",
    "        n_feat_next = n_features_next[conv_idx]\n",
    "        model.add(residual_blocks.building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                            n_feat_next,\n",
    "                                                            kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                            is_subsample=True,\n",
    "                                                            subsample=pool_sizes[conv_idx]\n",
    "                                                            ))\n",
    "\n",
    "        height_input, width_input = model.output_shape[2:]\n",
    "        # width_input  = int(width_input/pool_sizes[conv_idx][1])\n",
    "        num_channel_input = n_feat_next\n",
    "\n",
    "    # Add average pooling at the end:\n",
    "    print('Average pooling, from (%d,%d) to (1,1)' % (height_input, width_input))\n",
    "    model.add(AveragePooling2D(pool_size=(height_input, width_input)))\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_residual_model(is_mnist=True, img_channels=1, img_rows=28, img_cols=28):\n",
    "    model = keras.models.Sequential()\n",
    "    first_layer_channel = 128\n",
    "    if is_mnist: # size to be changed to 32,32\n",
    "        model.add(ZeroPadding2D((2,2), input_shape=(img_channels, img_rows, img_cols))) # resize (28,28)-->(32,32)\n",
    "        # the first conv \n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same'))\n",
    "    else:\n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same', input_shape=(img_channels, img_rows, img_cols)))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    # [residual-based Conv layers]\n",
    "    residual_blocks = design_for_residual_blocks(num_channel_input=first_layer_channel)\n",
    "    model.add(residual_blocks)\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    # [Classifier]    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # [END]\n",
    "    return model\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    is_mnist = True\n",
    "    is_cifar10 = not is_mnist\n",
    "\n",
    "    if is_mnist:\n",
    "        import scipy.io as sio\n",
    "        import numpy as np\n",
    "\n",
    "        img_rows, img_cols = 144, 144\n",
    "        img_channels = 1\n",
    "        WB = sio.loadmat('WB_small.mat')['WB_small']\n",
    "        Y_data = sio.loadmat('true.mat')['skt']\n",
    "        Y_data = (Y_data - min(Y_data)) / (max(Y_data) - min(Y_data))\n",
    "        X_data = np.reshape(WB, (100, 1, img_rows, img_cols))\n",
    "        X_train = X_data[0:80];\n",
    "        X_test = X_data[80:100]\n",
    "        Y_train = Y_data[0:80];\n",
    "        Y_test = Y_data[80:100]\n",
    "        print(' == MNIST ==')\n",
    "    else:\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "        img_rows, img_cols = 32, 32\n",
    "        img_channels = 3\n",
    "        print(' == CIFAR10 ==')\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    # X_train /= 255\n",
    "    # X_test /= 255\n",
    "    # X_train = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "    # X_test = (X_test - np.mean(X_test))/np.std(X_test)\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    model = get_residual_model(is_mnist=is_mnist, img_channels=img_channels, img_rows=img_rows, img_cols=img_cols)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # # autosave best Model\n",
    "    # best_model_file = \"./my_model_weights.h5\"\n",
    "    # best_model = ModelCheckpoint(best_model_file, verbose=1, save_best_only=True)\n",
    "    #\n",
    "#     model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_test, Y_test))#, callbacks=[best_model])\n",
    "    # score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "    # print('Test score:', score[0])\n",
    "    # print('Test accuracy:', score[1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
