{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Residual block by Keunwoo Choi (keunwoo.choi@qmul.ac.uk)\n",
    "\n",
    "It is based on \"Deep Residual Learning for Image Recognition\" (http://arxiv.org/abs/1512.03385)\n",
    "and \"Identity Mappings in Deep Residual Networks\" (http://arxiv.org/abs/1603.05027).\n",
    "'''\n",
    "import keras\n",
    "# from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Layer, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, merge\n",
    "from keras.models import Model\n",
    "import pdb\n",
    "\n",
    "# W1=sio.loadmat('W1_temp')['W1_temp']\n",
    "# W2=sio.loadmat('W2_temp')['W2_temp']\n",
    "# W3=sio.loadmat('W3_temp')['W3_temp']\n",
    "# W1=np.asarray(W1, dtype=np.float32)\n",
    "# W2=np.asarray(W2, dtype=np.float32)\n",
    "# W3=np.asarray(W3, dtype=np.float32)\n",
    "\n",
    "def building_residual_block(input_shape, n_feature_maps, n_feat_next, image_patch_sizes,conv_idx,\n",
    "                            kernel_sizes=None, kernel2_sizes=None, n_skip=2, is_subsample=False, \n",
    "                            subsample=None):\n",
    "    '''\n",
    "    [1] Building block of layers for residual learning.\n",
    "        Code based on https://github.com/ndronen/modeling/blob/master/modeling/residual.py\n",
    "        , but modification of (perhaps) incorrect relu(f)+x thing and it's for conv layer\n",
    "\n",
    "    [2] ----This comment used to be valid. Now it is not, but I failed to track since when.----\n",
    "        ----Now the comment below is incorrect, I am using strided convolution here.----\n",
    "        ----invalid comment------------------------------------------------------------------------------\n",
    "        | MaxPooling is used instead of strided convolution to make it easier                           | \n",
    "        | to set size(output of short-cut) == size(output of conv-layers).                              | \n",
    "        | If you want to remove MaxPooling,                                                             | \n",
    "        |    i) change (border_mode in Convolution2D in shortcut), 'same'-->'valid'                     | \n",
    "        |    ii) uncomment ZeroPadding2D in conv layers.                                                | \n",
    "        |        (Then the following Conv2D is not the first layer of this container anymore,           | \n",
    "        |         so you can remove the input_shape in the line 101, the line with comment #'OPTION' )  | \n",
    "        -------------------------------------------------------------------------------------------------\n",
    "\n",
    "    [3] It can be used for both cases whether it subsamples or not.\n",
    "\n",
    "    [4] In the short-cut connection, I used 1x1 convolution to increase #channel.\n",
    "        It occurs when is_expand_channels == True \n",
    "\n",
    "    input_shape = (None, num_channel, height, width) \n",
    "    n_feature_maps: number of feature maps. In ResidualNet it increases whenever image is downsampled.\n",
    "    kernel_sizes : list or tuple, (3,3) or [3,3] for example\n",
    "    n_skip       : number of layers to skip\n",
    "    is_subsample : If it is True, the layers subsamples by *subsample* to reduce the size.\n",
    "    subsample    : tuple, (2,2) or (1,2) for example. Used only if is_subsample==True\n",
    "    '''\n",
    "    # is_expand_channels == True when num_channels increases.\n",
    "    #    E.g. the very first residual block (e.g. 1->64, 3->128, 128->256, ...)\n",
    "    \n",
    "    import scipy.io as sio\n",
    "    #from keras.utils.theano_utils import sharedX\n",
    "    W1=sio.loadmat('W1_temp')['W1_temp']\n",
    "    W2=sio.loadmat('W2_temp')['W2_temp']\n",
    "    W3=sio.loadmat('W3_temp')['W3_temp']\n",
    "    W1=np.asarray(W1, dtype=np.float32)\n",
    "    W2=np.asarray(W2, dtype=np.float32)\n",
    "    W3=np.asarray(W3, dtype=np.float32)\n",
    "    \n",
    "        \n",
    "    kernel_row, kernel_col = kernel_sizes\n",
    "    kernel_row2, kernel_col2 = kernel2_sizes\n",
    "    \n",
    "#     if n_feature_maps!=n_feat_next:\n",
    "    print('conv_idx=',conv_idx)\n",
    "    kernel_sizes_pre=image_patch_sizes[conv_idx-1]\n",
    "    kernel_row_pre, kernel_col_pre = kernel_sizes_pre\n",
    "        \n",
    "    # ***** VERBOSE_PART ***** \n",
    "    print ('   - New residual block with')\n",
    "    print ('      input shape:', input_shape)\n",
    "    print ('      kernel size:', kernel_sizes)  \n",
    "    \n",
    "    is_expand_channels = not (input_shape[0] == n_feature_maps) \n",
    "    if is_expand_channels:\n",
    "        print ('      - Input channels: %d ---> num feature maps on out: %d' % (input_shape[0], n_feature_maps)  )\n",
    "    if is_subsample:\n",
    "        print ('      - with subsample:', subsample)\n",
    "    # set input\n",
    "    x = Input(shape=(input_shape))\n",
    "    # ***** SHORTCUT PATH *****\n",
    "    if is_subsample: # subsample (+ channel expansion if needed)\n",
    "        shortcut_y = Convolution2D(n_feature_maps, kernel_sizes[0], kernel_sizes[1], \n",
    "                                    subsample=subsample,\n",
    "                                    border_mode='same')(x)\n",
    "        print ('short cut kernel sizes=',n_feature_maps, kernel_sizes[0], kernel_sizes[1])\n",
    "    else: # channel expansion only (e.g. the very first layer of the whole networks)\n",
    "        if is_expand_channels:\n",
    "            shortcut_y = Convolution2D(n_feature_maps, 1, 1, border_mode='same')(x)\n",
    "        else:\n",
    "            # if no subsample and no channel expension, there's nothing to add on the shortcut.\n",
    "            shortcut_y = x\n",
    "        print ('short cut kernel sizes=',n_feature_maps, kernel_sizes[0], kernel_sizes[1])\n",
    "    # ***** CONVOLUTION_PATH ***** \n",
    "    conv_y = x\n",
    "    for i in range(n_skip):\n",
    "        conv_y = BatchNormalization(axis=1, mode=2)(conv_y)        \n",
    "        conv_y = Activation('relu')(conv_y)\n",
    "        if i==0 and is_subsample: # [Subsample at layer 0 if needed]\n",
    "            conv_y = Convolution2D(n_feature_maps, kernel_row_pre, kernel_col_pre,\n",
    "                                    subsample=subsample,\n",
    "                                    border_mode='same')(conv_y)  \n",
    "            print ('kernel sizes 1=',conv_idx,n_feature_maps, kernel_row_pre, kernel_col_pre)\n",
    "        else:        \n",
    "            conv_y = Convolution2D(n_feature_maps, kernel_row, kernel_col, border_mode='same')(conv_y)\n",
    "            print ('kernel sizes 2=',conv_idx,n_feature_maps, kernel_row, kernel_col)\n",
    "    # output\n",
    "    y = merge([shortcut_y, conv_y], mode='sum')\n",
    "    block = Model(input=x, output=y)\n",
    "    print ('        -- model was built.')\n",
    "    print(block.layers[3].W.get_value().shape)\n",
    "#     block.summary()\n",
    "    \n",
    "    if conv_idx==4:\n",
    "        print('feature=40, W size=',block.layers[3].W.get_value().shape)\n",
    "        print('feature=40, W2 size=',W2.shape)\n",
    "        block.layers[3].W.set_value(W2)\n",
    "#         block.layers[6].W.set_value(W2)\n",
    "    elif conv_idx==9:\n",
    "        print('feature=288, W size=',block.layers[3].W.get_value().shape)\n",
    "        print('feature=288, W3 size=',W3.shape)\n",
    "        block.layers[3].W.set_value(W3)\n",
    "#         block.layers[6].W.set_value(W3)\n",
    "    return block\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == MNIST ==\n",
      "X_train shape: (80L, 1L, 144L, 144L)\n",
      "80 train samples\n",
      "20 test samples\n",
      "conv_idx= 0\n",
      "   - New residual block with\n",
      "      input shape: (24, 144, 144)\n",
      "      kernel size: [6, 6]\n",
      "short cut kernel sizes= 24 6 6\n",
      "kernel sizes 2= 0 24 6 6\n",
      "kernel sizes 2= 0 24 6 6\n",
      "        -- model was built.\n",
      "(24L, 24L, 6L, 6L)\n",
      "conv_idx= 1\n",
      "   - New residual block with\n",
      "      input shape: (24, 144, 144)\n",
      "      kernel size: [6, 6]\n",
      "short cut kernel sizes= 24 6 6\n",
      "kernel sizes 2= 1 24 6 6\n",
      "kernel sizes 2= 1 24 6 6\n",
      "        -- model was built.\n",
      "(24L, 24L, 6L, 6L)\n",
      "conv_idx= 2\n",
      "   - New residual block with\n",
      "      input shape: (24, 144, 144)\n",
      "      kernel size: [6, 6]\n",
      "short cut kernel sizes= 24 6 6\n",
      "kernel sizes 2= 2 24 6 6\n",
      "kernel sizes 2= 2 24 6 6\n",
      "        -- model was built.\n",
      "(24L, 24L, 6L, 6L)\n",
      "conv_idx= 3\n",
      "   - New residual block with\n",
      "      input shape: (24, 144, 144)\n",
      "      kernel size: [6, 6]\n",
      "short cut kernel sizes= 24 6 6\n",
      "kernel sizes 2= 3 24 6 6\n",
      "kernel sizes 2= 3 24 6 6\n",
      "        -- model was built.\n",
      "(24L, 24L, 6L, 6L)\n",
      "conv_idx= 4\n",
      "   - New residual block with\n",
      "      input shape: (24, 144, 144)\n",
      "      kernel size: [9, 9]\n",
      "short cut kernel sizes= 24 9 9\n",
      "kernel sizes 2= 4 24 9 9\n",
      "kernel sizes 2= 4 24 9 9\n",
      "        -- model was built.\n",
      "(24L, 24L, 9L, 9L)\n",
      "conv_idx= 4\n",
      "   - New residual block with\n",
      "      input shape: (24, 144, 144)\n",
      "      kernel size: [9, 9]\n",
      "      - Input channels: 24 ---> num feature maps on out: 40\n",
      "      - with subsample: (2, 2)\n",
      "short cut kernel sizes= 40 9 9\n",
      "kernel sizes 1= 4 40 6 6\n",
      "kernel sizes 2= 4 40 9 9\n",
      "        -- model was built.\n",
      "(40L, 24L, 6L, 6L)\n",
      "conv_idx= 5\n",
      "   - New residual block with\n",
      "      input shape: (40, 72, 72)\n",
      "      kernel size: [9, 9]\n",
      "short cut kernel sizes= 40 9 9\n",
      "kernel sizes 2= 5 40 9 9\n",
      "kernel sizes 2= 5 40 9 9\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "conv_idx= 6\n",
      "   - New residual block with\n",
      "      input shape: (40, 72, 72)\n",
      "      kernel size: [9, 9]\n",
      "short cut kernel sizes= 40 9 9\n",
      "kernel sizes 2= 6 40 9 9\n",
      "kernel sizes 2= 6 40 9 9\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "conv_idx= 7\n",
      "   - New residual block with\n",
      "      input shape: (40, 72, 72)\n",
      "      kernel size: [9, 9]\n",
      "short cut kernel sizes= 40 9 9\n",
      "kernel sizes 2= 7 40 9 9\n",
      "kernel sizes 2= 7 40 9 9\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "conv_idx= 8\n",
      "   - New residual block with\n",
      "      input shape: (40, 72, 72)\n",
      "      kernel size: [9, 9]\n",
      "short cut kernel sizes= 40 9 9\n",
      "kernel sizes 2= 8 40 9 9\n",
      "kernel sizes 2= 8 40 9 9\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "conv_idx= 9\n",
      "   - New residual block with\n",
      "      input shape: (40, 72, 72)\n",
      "      kernel size: [9, 9]\n",
      "short cut kernel sizes= 40 9 9\n",
      "kernel sizes 2= 9 40 9 9\n",
      "kernel sizes 2= 9 40 9 9\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "conv_idx= 9\n",
      "   - New residual block with\n",
      "      input shape: (40, 72, 72)\n",
      "      kernel size: [9, 9]\n",
      "      - Input channels: 40 ---> num feature maps on out: 288\n",
      "      - with subsample: (2, 2)\n",
      "short cut kernel sizes= 288 9 9\n",
      "kernel sizes 1= 9 288 9 9\n",
      "kernel sizes 2= 9 288 9 9\n",
      "        -- model was built.\n",
      "(288L, 40L, 9L, 9L)\n",
      "conv_idx= 10\n",
      "   - New residual block with\n",
      "      input shape: (288, 36, 36)\n",
      "      kernel size: [9, 9]\n",
      "short cut kernel sizes= 288 9 9\n",
      "kernel sizes 2= 10 288 9 9\n",
      "kernel sizes 2= 10 288 9 9\n",
      "        -- model was built.\n",
      "(288L, 288L, 9L, 9L)\n",
      "conv_idx= 11\n",
      "   - New residual block with\n",
      "      input shape: (288, 36, 36)\n",
      "      kernel size: [9, 9]\n",
      "short cut kernel sizes= 288 9 9\n",
      "kernel sizes 2= 11 288 9 9\n",
      "kernel sizes 2= 11 288 9 9\n",
      "        -- model was built.\n",
      "(288L, 288L, 9L, 9L)\n",
      "conv_idx= 12\n",
      "   - New residual block with\n",
      "      input shape: (288, 36, 36)\n",
      "      kernel size: [9, 9]\n",
      "      - Input channels: 288 ---> num feature maps on out: 312\n",
      "short cut kernel sizes= 312 9 9\n",
      "kernel sizes 2= 12 312 9 9\n",
      "kernel sizes 2= 12 312 9 9\n",
      "        -- model was built.\n",
      "(312L, 288L, 9L, 9L)\n",
      "conv_idx= 12\n",
      "   - New residual block with\n",
      "      input shape: (312, 36, 36)\n",
      "      kernel size: [9, 9]\n",
      "      - Input channels: 312 ---> num feature maps on out: 288\n",
      "      - with subsample: (2, 2)\n",
      "short cut kernel sizes= 288 9 9\n",
      "kernel sizes 1= 12 288 9 9\n",
      "kernel sizes 2= 12 288 9 9\n",
      "        -- model was built.\n",
      "(288L, 312L, 9L, 9L)\n",
      "conv_idx= 13\n",
      "   - New residual block with\n",
      "      input shape: (288, 18, 18)\n",
      "      kernel size: [9, 9]\n",
      "      - Input channels: 288 ---> num feature maps on out: 312\n",
      "short cut kernel sizes= 312 9 9\n",
      "kernel sizes 2= 13 312 9 9\n",
      "kernel sizes 2= 13 312 9 9\n",
      "        -- model was built.\n",
      "(312L, 288L, 9L, 9L)\n",
      "conv_idx= 14\n",
      "   - New residual block with\n",
      "      input shape: (312, 18, 18)\n",
      "      kernel size: [9, 9]\n",
      "      - Input channels: 312 ---> num feature maps on out: 576\n",
      "short cut kernel sizes= 576 9 9\n",
      "kernel sizes 2= 14 576 9 9\n",
      "kernel sizes 2= 14 576 9 9\n",
      "        -- model was built.\n",
      "(576L, 312L, 9L, 9L)\n",
      "conv_idx= 14\n",
      "   - New residual block with\n",
      "      input shape: (576, 18, 18)\n",
      "      kernel size: [9, 9]\n",
      "      - Input channels: 576 ---> num feature maps on out: 312\n",
      "      - with subsample: (2, 2)\n",
      "short cut kernel sizes= 312 9 9\n",
      "kernel sizes 1= 14 312 9 9\n",
      "kernel sizes 2= 14 312 9 9\n",
      "        -- model was built.\n",
      "(312L, 576L, 9L, 9L)\n",
      "conv_idx= 15\n",
      "   - New residual block with\n",
      "      input shape: (312, 9, 9)\n",
      "      kernel size: [9, 9]\n",
      "      - Input channels: 312 ---> num feature maps on out: 576\n",
      "short cut kernel sizes= 576 9 9\n",
      "kernel sizes 2= 15 576 9 9\n",
      "kernel sizes 2= 15 576 9 9\n",
      "        -- model was built.\n",
      "(576L, 312L, 9L, 9L)\n",
      "conv_idx= 16\n",
      "   - New residual block with\n",
      "      input shape: (576, 9, 9)\n",
      "      kernel size: [9, 9]\n",
      "short cut kernel sizes= 576 9 9\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DeepCopyOp: the copy failed!\nApply node that caused the error: DeepCopyOp(convolution2d_101_W)\nToposort index: 0\nInputs types: [CudaNdarrayType(float32, 4D)]\nInputs shapes: [(576, 576, 9, 9)]\nInputs strides: [(46656, 81, 9, 1)]\nInputs values: ['not shown']\nOutputs clients: [['output']]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d2a0e48ee7ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_residual_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_mnist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_mnist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d2a0e48ee7ec>\u001b[0m in \u001b[0;36mget_residual_model\u001b[1;34m(is_mnist, img_channels, img_rows, img_cols)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# [residual-based Conv layers]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mresidual_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdesign_for_residual_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_channel_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_layer_channel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;31m#     residual_blocks.layers[2].W.get_value().shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresidual_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d2a0e48ee7ec>\u001b[0m in \u001b[0;36mdesign_for_residual_blocks\u001b[1;34m(num_channel_input)\u001b[0m\n\u001b[0;32m     61\u001b[0m                                                             \u001b[0mn_feat_here\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_feat_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_patch_sizes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                                                             \u001b[0mkernel_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_patch_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                                                             \u001b[0mkernel2_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_patch_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconv_idx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                                                             ))\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-077f934cf865>\u001b[0m in \u001b[0;36mbuilding_residual_block\u001b[1;34m(input_shape, n_feature_maps, n_feat_next, image_patch_sizes, conv_idx, kernel_sizes, kernel2_sizes, n_skip, is_subsample, subsample)\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'kernel sizes 1='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_feature_maps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_row_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_col_pre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0mconv_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_feature_maps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'kernel sizes 2='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_feature_maps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;31m# output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[1;31m# this will call layer.build() if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m             \u001b[0minput_added\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\topology.pyc\u001b[0m in \u001b[0;36madd_inbound_node\u001b[1;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\topology.pyc\u001b[0m in \u001b[0;36mcreate_node\u001b[1;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[0moutput_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;31m# TODO: try to auto-infer shape if exception is raised by get_output_shape_for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\layers\\convolutional.pyc\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    351\u001b[0m                           \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mborder_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                           \u001b[0mdim_ordering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m                           filter_shape=self.W_shape)\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_ordering\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'th'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\backend\\theano_backend.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(x, kernel, strides, border_mode, dim_ordering, image_shape, filter_shape, filter_dilation)\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_preprocess_conv2d_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m     \u001b[0mth_border_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_preprocess_border_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mborder_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1125\u001b[1;33m     \u001b[0mnp_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1126\u001b[0m     \u001b[0mimage_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_preprocess_image_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[0mfilter_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_preprocess_filter_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\theano\\gof\\graph.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, inputs_to_values)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DeepCopyOp: the copy failed!\nApply node that caused the error: DeepCopyOp(convolution2d_101_W)\nToposort index: 0\nInputs types: [CudaNdarrayType(float32, 4D)]\nInputs shapes: [(576, 576, 9, 9)]\nInputs strides: [(46656, 81, 9, 1)]\nInputs values: ['not shown']\nOutputs clients: [['output']]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.setrecursionlimit(99999)\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import ZeroPadding2D, AveragePooling2D, Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "nb_classes = 1\n",
    "nb_epoch = 20\n",
    "\n",
    "def compute_padding_length(length_before, stride, length_conv):\n",
    "    ''' Assumption: you want the subsampled result has a length of floor(original_length/stride).\n",
    "    '''\n",
    "    N = length_before\n",
    "    F = length_conv\n",
    "    S = stride\n",
    "    if S == F:\n",
    "        return 0\n",
    "    if S == 1:\n",
    "        return (F-1)/2\n",
    "    for P in range(S):\n",
    "        if (N-F+2*P)/S + 1 == N/S:\n",
    "            return P\n",
    "    return 0\n",
    "\n",
    "def design_for_residual_blocks(num_channel_input=1):\n",
    "    ''''''\n",
    "    model = Sequential() # it's a CONTAINER, not MODEL\n",
    "    # set numbers\n",
    "    num_big_blocks = 17\n",
    "#     image_patch_sizes = [[3,3]]*(num_big_blocks+1)\n",
    "    image_patch_sizes = [[6,6],[6,6],[6,6],[6,6],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],\n",
    "                        [9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9]]\n",
    "    pool_sizes = [(2,2)]*num_big_blocks\n",
    "#     n_features =      [24,24,24,24,40,40,40, 288,288, 288,512,512, 1024]\n",
    "#     n_features_next = [24,24,24,40,40,40,288,288,288, 512,512,1024,1024]\n",
    "    n_features =      [24,24,24,24,24,40,40,40,40,40, 288,288,312,312,576,576,576]\n",
    "    n_features_next = [24,24,24,24,40,40,40,40,40,288,288,288,288,312,312,576,576]\n",
    "    height_input = 144\n",
    "    width_input = 144\n",
    "        \n",
    "    for conv_idx in range(num_big_blocks):    \n",
    "        n_feat_here = n_features[conv_idx]\n",
    "        n_feat_next = n_features_next[conv_idx]\n",
    "        # residual block 0\n",
    "        model.add(building_residual_block(  (num_channel_input, height_input, width_input),\n",
    "                                                            n_feat_here,n_feat_next,image_patch_sizes,conv_idx,\n",
    "                                                            kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                            kernel2_sizes=image_patch_sizes[conv_idx+1]\n",
    "                                                            ))\n",
    "\n",
    "        # residual block 1 (you can add it as you want (and your resources allow..))\n",
    "        if False:\n",
    "            model.add(building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                                n_feat_here,\n",
    "                                                                kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                                kernel2_sizes=image_patch_sizes[conv_idx+1]\n",
    "                                                                ))\n",
    "        \n",
    "        # the last residual block N-1\n",
    "        # the last one : pad zeros, subsamples, and increase #channels\n",
    "        pad_height = compute_padding_length(height_input, pool_sizes[conv_idx][0], image_patch_sizes[conv_idx][0])\n",
    "        pad_width = compute_padding_length(width_input, pool_sizes[conv_idx][1], image_patch_sizes[conv_idx][1])\n",
    "        model.add(ZeroPadding2D(padding=(pad_height,pad_width))) \n",
    "        height_input += 2*pad_height\n",
    "        width_input += 2*pad_width\n",
    "        n_feat_next = n_features_next[conv_idx]\n",
    "        if n_features[conv_idx] != n_features_next[conv_idx]:\n",
    "            model.add(building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                                n_feat_next,n_feat_next,image_patch_sizes,conv_idx,\n",
    "                                                                kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                                kernel2_sizes=image_patch_sizes[conv_idx+1],\n",
    "                                                                is_subsample=True,\n",
    "                                                                subsample=pool_sizes[conv_idx]\n",
    "                                                                ))\n",
    "\n",
    "        height_input, width_input = model.output_shape[2:]\n",
    "        # width_input  = int(width_input/pool_sizes[conv_idx][1])\n",
    "        num_channel_input = n_feat_next\n",
    "\n",
    "    # Add average pooling at the end:\n",
    "    print('Average pooling, from (%d,%d) to (1,1)' % (height_input, width_input))\n",
    "    model.add(AveragePooling2D(pool_size=(height_input, width_input)))\n",
    "    return model\n",
    "\n",
    "def get_residual_model(is_mnist=True, img_channels=1, img_rows=28, img_cols=28):\n",
    "    model = keras.models.Sequential()\n",
    "    first_layer_channel = 24\n",
    "    \n",
    "    W1=sio.loadmat('W1_temp')['W1_temp']\n",
    "    W1=np.asarray(W1, dtype=np.float32)\n",
    "    \n",
    "    if is_mnist: # size to be changed to 32,32\n",
    "        model.add(ZeroPadding2D((2,2), input_shape=(img_channels, img_rows, img_cols))) # resize (28,28)-->(32,32)\n",
    "        # the first conv \n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same'))\n",
    "    else:\n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same', input_shape=(img_channels, img_rows, img_cols)))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    # [residual-based Conv layers]\n",
    "    residual_blocks = design_for_residual_blocks(num_channel_input=first_layer_channel)\n",
    "#     residual_blocks.layers[2].W.get_value().shape\n",
    "    model.add(residual_blocks)\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    # [Classifier]    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('linear'))\n",
    "    # [END]\n",
    "#     print(model.layers[1].W.get_value().shape)\n",
    "    model.summary()\n",
    "    print('feature=24, W size=',model.layers[1].W.get_value().shape)\n",
    "    return model\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    is_mnist = True\n",
    "    is_cifar10 = not is_mnist\n",
    "\n",
    "    if is_mnist:\n",
    "        import scipy.io as sio\n",
    "        import numpy as np\n",
    "\n",
    "        img_rows, img_cols = 144, 144\n",
    "        img_channels = 1\n",
    "        WB = sio.loadmat('WB_small.mat')['WB_small']\n",
    "        Y_data = sio.loadmat('true.mat')['skt']\n",
    "        Y_data = (Y_data - min(Y_data)) / (max(Y_data) - min(Y_data))\n",
    "        X_data = np.reshape(WB, (100, 1, img_rows, img_cols))\n",
    "        X_train = X_data[0:80];\n",
    "        X_test = X_data[80:100]\n",
    "        Y_train = Y_data[0:80];\n",
    "        Y_test = Y_data[80:100]\n",
    "        print(' == MNIST ==')\n",
    "    else:\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "        img_rows, img_cols = 32, 32\n",
    "        img_channels = 3\n",
    "        print(' == CIFAR10 ==')\n",
    "\n",
    "    import scipy.io as sio\n",
    "    #from keras.utils.theano_utils import sharedX\n",
    "    W1=sio.loadmat('W1_temp')['W1_temp']\n",
    "    W1=np.asarray(W1, dtype=np.float32)\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    # X_train /= 255\n",
    "    # X_test /= 255\n",
    "    # X_train = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "    # X_test = (X_test - np.mean(X_test))/np.std(X_test)\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    model = get_residual_model(is_mnist=is_mnist, img_channels=img_channels, img_rows=img_rows, img_cols=img_cols)\n",
    "    model.layers[1].W.set_value(W1)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_125 (ZeroPadding2D)(None, 1, 148, 148)   0           zeropadding2d_input_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_350 (Convolution2D)(None, 24, 148, 148)  240         zeropadding2d_125[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_350 (Activation)      (None, 24, 148, 148)  0           convolution2d_350[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "sequential_46 (Sequential)       (None, 288, 1, 1)     22921000    activation_350[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_322 (BatchNorm(None, 288, 1, 1)     576         sequential_46[1][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_365 (Activation)      (None, 288, 1, 1)     0           batchnormalization_322[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)             (None, 288)           0           activation_365[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 1)             289         flatten_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_366 (Activation)      (None, 1)             0           dense_21[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 22922105\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\r\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpcfojqi/d46bacc617ffda419c1776ea823de0be.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpcfojqi/d46bacc617ffda419c1776ea823de0be.exp\r\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GpuDnnConv images and kernel must have the same stack size\n\nApply node that caused the error: GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})\nToposort index: 731\nInputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), <theano.gof.type.CDataType object at 0x00000000437BC390>, Scalar(float32), Scalar(float32)]\nInputs shapes: [(10, 24, 148, 148), (24, 1, 6, 6), (10, 24, 149, 149), 'No shapes', (), ()]\nInputs strides: [(525696, 21904, 148, 1), (36, 0, 6, 1), (532824, 22201, 149, 1), 'No strides', (), ()]\nInputs values: ['not shown', 'not shown', 'not shown', <PyCObject object at 0x000000003B64ACB0>, 1.0, 0.0]\nInputs name: ('image', 'kernel', 'output', 'descriptor', 'alpha', 'beta')\n\nOutputs clients: [[GpuSubtensor{int64:int64:int8, int64:int64:int8, int64:int64:int8, int64:int64:int8}(GpuDnnConv{algo='small', inplace=True}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1}, Constant{0}, Constant{24}, Constant{1}, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-a70a8b48b5ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1102\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    820\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\backend\\theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: GpuDnnConv images and kernel must have the same stack size\n\nApply node that caused the error: GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})\nToposort index: 731\nInputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), <theano.gof.type.CDataType object at 0x00000000437BC390>, Scalar(float32), Scalar(float32)]\nInputs shapes: [(10, 24, 148, 148), (24, 1, 6, 6), (10, 24, 149, 149), 'No shapes', (), ()]\nInputs strides: [(525696, 21904, 148, 1), (36, 0, 6, 1), (532824, 22201, 149, 1), 'No strides', (), ()]\nInputs values: ['not shown', 'not shown', 'not shown', <PyCObject object at 0x000000003B64ACB0>, 1.0, 0.0]\nInputs name: ('image', 'kernel', 'output', 'descriptor', 'alpha', 'beta')\n\nOutputs clients: [[GpuSubtensor{int64:int64:int8, int64:int64:int8, int64:int64:int8, int64:int64:int8}(GpuDnnConv{algo='small', inplace=True}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1}, Constant{0}, Constant{24}, Constant{1}, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, validation_data=(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
