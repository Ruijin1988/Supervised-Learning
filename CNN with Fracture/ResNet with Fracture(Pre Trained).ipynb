{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpw2tp8m/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpw2tp8m/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: Quadro K2000 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "'''Residual block by Keunwoo Choi (keunwoo.choi@qmul.ac.uk)\n",
    "\n",
    "It is based on \"Deep Residual Learning for Image Recognition\" (http://arxiv.org/abs/1512.03385)\n",
    "and \"Identity Mappings in Deep Residual Networks\" (http://arxiv.org/abs/1603.05027).\n",
    "'''\n",
    "import keras\n",
    "# from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Layer, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, merge\n",
    "from keras.models import Model\n",
    "import pdb\n",
    "\n",
    "# W1=sio.loadmat('W1_temp')['W1_temp']\n",
    "# W2=sio.loadmat('W2_temp')['W2_temp']\n",
    "# W3=sio.loadmat('W3_temp')['W3_temp']\n",
    "# W1=np.asarray(W1, dtype=np.float32)\n",
    "# W2=np.asarray(W2, dtype=np.float32)\n",
    "# W3=np.asarray(W3, dtype=np.float32)\n",
    "\n",
    "def building_residual_block(input_shape, n_feature_maps, n_feat_next, image_patch_sizes,conv_idx,\n",
    "                            kernel_sizes=None, kernel2_sizes=None, n_skip=2, is_subsample=False, \n",
    "                            subsample=None):\n",
    "    '''\n",
    "    [1] Building block of layers for residual learning.\n",
    "        Code based on https://github.com/ndronen/modeling/blob/master/modeling/residual.py\n",
    "        , but modification of (perhaps) incorrect relu(f)+x thing and it's for conv layer\n",
    "\n",
    "    [2] ----This comment used to be valid. Now it is not, but I failed to track since when.----\n",
    "        ----Now the comment below is incorrect, I am using strided convolution here.----\n",
    "        ----invalid comment------------------------------------------------------------------------------\n",
    "        | MaxPooling is used instead of strided convolution to make it easier                           | \n",
    "        | to set size(output of short-cut) == size(output of conv-layers).                              | \n",
    "        | If you want to remove MaxPooling,                                                             | \n",
    "        |    i) change (border_mode in Convolution2D in shortcut), 'same'-->'valid'                     | \n",
    "        |    ii) uncomment ZeroPadding2D in conv layers.                                                | \n",
    "        |        (Then the following Conv2D is not the first layer of this container anymore,           | \n",
    "        |         so you can remove the input_shape in the line 101, the line with comment #'OPTION' )  | \n",
    "        -------------------------------------------------------------------------------------------------\n",
    "\n",
    "    [3] It can be used for both cases whether it subsamples or not.\n",
    "\n",
    "    [4] In the short-cut connection, I used 1x1 convolution to increase #channel.\n",
    "        It occurs when is_expand_channels == True \n",
    "\n",
    "    input_shape = (None, num_channel, height, width) \n",
    "    n_feature_maps: number of feature maps. In ResidualNet it increases whenever image is downsampled.\n",
    "    kernel_sizes : list or tuple, (3,3) or [3,3] for example\n",
    "    n_skip       : number of layers to skip\n",
    "    is_subsample : If it is True, the layers subsamples by *subsample* to reduce the size.\n",
    "    subsample    : tuple, (2,2) or (1,2) for example. Used only if is_subsample==True\n",
    "    '''\n",
    "    # is_expand_channels == True when num_channels increases.\n",
    "    #    E.g. the very first residual block (e.g. 1->64, 3->128, 128->256, ...)\n",
    "    \n",
    "    import scipy.io as sio\n",
    "    #from keras.utils.theano_utils import sharedX\n",
    "    W1=sio.loadmat('W1_temp')['W1_temp']\n",
    "    W2=sio.loadmat('W2_temp')['W2_temp']\n",
    "    W3=sio.loadmat('W3_temp')['W3_temp']\n",
    "    W1=np.asarray(W1, dtype=np.float32)\n",
    "    W2=np.asarray(W2, dtype=np.float32)\n",
    "    W3=np.asarray(W3, dtype=np.float32)\n",
    "    \n",
    "        \n",
    "    kernel_row, kernel_col = kernel_sizes\n",
    "    kernel_row2, kernel_col2 = kernel2_sizes\n",
    "    \n",
    "#     if n_feature_maps!=n_feat_next:\n",
    "    print('conv_idx=',conv_idx)\n",
    "    kernel_sizes_pre=image_patch_sizes[conv_idx-1]\n",
    "    kernel_row_pre, kernel_col_pre = kernel_sizes_pre\n",
    "        \n",
    "    # ***** VERBOSE_PART ***** \n",
    "    print ('   - New residual block with')\n",
    "    print ('      input shape:', input_shape)\n",
    "    print ('      kernel size:', kernel_sizes)  \n",
    "    \n",
    "    is_expand_channels = not (input_shape[0] == n_feature_maps) \n",
    "    if is_expand_channels:\n",
    "        print ('      - Input channels: %d ---> num feature maps on out: %d' % (input_shape[0], n_feature_maps)  )\n",
    "    if is_subsample:\n",
    "        print ('      - with subsample:', subsample)\n",
    "    # set input\n",
    "    x = Input(shape=(input_shape))\n",
    "    # ***** SHORTCUT PATH *****\n",
    "    if is_subsample: # subsample (+ channel expansion if needed)\n",
    "        shortcut_y = Convolution2D(n_feature_maps, kernel_sizes[0], kernel_sizes[1], \n",
    "                                    subsample=subsample,\n",
    "                                    border_mode='same')(x)\n",
    "        print ('short cut kernel sizes=',n_feature_maps, kernel_sizes[0], kernel_sizes[1])\n",
    "    else: # channel expansion only (e.g. the very first layer of the whole networks)\n",
    "        if is_expand_channels:\n",
    "            shortcut_y = Convolution2D(n_feature_maps, 1, 1, border_mode='same')(x)\n",
    "        else:\n",
    "            # if no subsample and no channel expension, there's nothing to add on the shortcut.\n",
    "            shortcut_y = x\n",
    "        print ('short cut kernel sizes=',n_feature_maps, kernel_sizes[0], kernel_sizes[1])\n",
    "    # ***** CONVOLUTION_PATH ***** \n",
    "    conv_y = x\n",
    "    for i in range(n_skip):\n",
    "        conv_y = BatchNormalization(axis=1, mode=2)(conv_y)        \n",
    "        conv_y = Activation('relu')(conv_y)\n",
    "        if i==0 and is_subsample: # [Subsample at layer 0 if needed]\n",
    "            conv_y = Convolution2D(n_feature_maps, kernel_row_pre, kernel_col_pre,\n",
    "                                    subsample=subsample,\n",
    "                                    border_mode='same')(conv_y)  \n",
    "            print ('kernel sizes 1=',conv_idx,n_feature_maps, kernel_row_pre, kernel_col_pre)\n",
    "        else:        \n",
    "            conv_y = Convolution2D(n_feature_maps, kernel_row, kernel_col, border_mode='same')(conv_y)\n",
    "            print ('kernel sizes 2=',conv_idx,n_feature_maps, kernel_row, kernel_col)\n",
    "    # output\n",
    "    y = merge([shortcut_y, conv_y], mode='sum')\n",
    "    block = Model(input=x, output=y)\n",
    "    print ('        -- model was built.')\n",
    "    print(block.layers[3].W.get_value().shape)\n",
    "#     block.summary()\n",
    "    \n",
    "    if conv_idx==4:\n",
    "        print('feature=40, W size=',block.layers[3].W.get_value().shape)\n",
    "        print('feature=40, W2 size=',W2.shape)\n",
    "        block.layers[3].W.set_value(W2)\n",
    "#         block.layers[6].W.set_value(W2)\n",
    "    elif conv_idx==9:\n",
    "        print('feature=288, W size=',block.layers[3].W.get_value().shape)\n",
    "        print('feature=288, W3 size=',W3.shape)\n",
    "        block.layers[3].W.set_value(W3)\n",
    "#         block.layers[6].W.set_value(W3)\n",
    "    return block\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == MNIST ==\n",
      "X_train shape: (80L, 1L, 144L, 144L)\n",
      "80 train samples\n",
      "20 test samples\n",
      "('conv_idx=', 0)\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 144, 144))\n",
      "('      kernel size:', [6, 6])\n",
      "('short cut kernel sizes=', 24, 6, 6)\n",
      "('kernel sizes 2=', 0, 24, 6, 6)\n",
      "('kernel sizes 2=', 0, 24, 6, 6)\n",
      "        -- model was built.\n",
      "(24L, 24L, 6L, 6L)\n",
      "('conv_idx=', 1)\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 144, 144))\n",
      "('      kernel size:', [6, 6])\n",
      "('short cut kernel sizes=', 24, 6, 6)\n",
      "('kernel sizes 2=', 1, 24, 6, 6)\n",
      "('kernel sizes 2=', 1, 24, 6, 6)\n",
      "        -- model was built.\n",
      "(24L, 24L, 6L, 6L)\n",
      "('conv_idx=', 2)\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 144, 144))\n",
      "('      kernel size:', [6, 6])\n",
      "('short cut kernel sizes=', 24, 6, 6)\n",
      "('kernel sizes 2=', 2, 24, 6, 6)\n",
      "('kernel sizes 2=', 2, 24, 6, 6)\n",
      "        -- model was built.\n",
      "(24L, 24L, 6L, 6L)\n",
      "('conv_idx=', 3)\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 144, 144))\n",
      "('      kernel size:', [6, 6])\n",
      "('short cut kernel sizes=', 24, 6, 6)\n",
      "('kernel sizes 2=', 3, 24, 6, 6)\n",
      "('kernel sizes 2=', 3, 24, 6, 6)\n",
      "        -- model was built.\n",
      "(24L, 24L, 6L, 6L)\n",
      "('conv_idx=', 4)\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 144, 144))\n",
      "('      kernel size:', [9, 9])\n",
      "('short cut kernel sizes=', 24, 9, 9)\n",
      "('kernel sizes 2=', 4, 24, 9, 9)\n",
      "('kernel sizes 2=', 4, 24, 9, 9)\n",
      "        -- model was built.\n",
      "(24L, 24L, 9L, 9L)\n",
      "('feature=40, W size=', (24L, 24L, 9L, 9L))\n",
      "('feature=40, W2 size=', (40L, 24L, 9L, 9L))\n",
      "('conv_idx=', 4)\n",
      "   - New residual block with\n",
      "('      input shape:', (24, 144, 144))\n",
      "('      kernel size:', [9, 9])\n",
      "      - Input channels: 24 ---> num feature maps on out: 40\n",
      "('      - with subsample:', (2, 2))\n",
      "('short cut kernel sizes=', 40, 9, 9)\n",
      "('kernel sizes 1=', 4, 40, 6, 6)\n",
      "('kernel sizes 2=', 4, 40, 9, 9)\n",
      "        -- model was built.\n",
      "(40L, 24L, 6L, 6L)\n",
      "('feature=40, W size=', (40L, 24L, 6L, 6L))\n",
      "('feature=40, W2 size=', (40L, 24L, 9L, 9L))\n",
      "('conv_idx=', 5)\n",
      "   - New residual block with\n",
      "('      input shape:', (40, 72, 72))\n",
      "('      kernel size:', [9, 9])\n",
      "('short cut kernel sizes=', 40, 9, 9)\n",
      "('kernel sizes 2=', 5, 40, 9, 9)\n",
      "('kernel sizes 2=', 5, 40, 9, 9)\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "('conv_idx=', 6)\n",
      "   - New residual block with\n",
      "('      input shape:', (40, 72, 72))\n",
      "('      kernel size:', [9, 9])\n",
      "('short cut kernel sizes=', 40, 9, 9)\n",
      "('kernel sizes 2=', 6, 40, 9, 9)\n",
      "('kernel sizes 2=', 6, 40, 9, 9)\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "('conv_idx=', 7)\n",
      "   - New residual block with\n",
      "('      input shape:', (40, 72, 72))\n",
      "('      kernel size:', [9, 9])\n",
      "('short cut kernel sizes=', 40, 9, 9)\n",
      "('kernel sizes 2=', 7, 40, 9, 9)\n",
      "('kernel sizes 2=', 7, 40, 9, 9)\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "('conv_idx=', 8)\n",
      "   - New residual block with\n",
      "('      input shape:', (40, 72, 72))\n",
      "('      kernel size:', [9, 9])\n",
      "('short cut kernel sizes=', 40, 9, 9)\n",
      "('kernel sizes 2=', 8, 40, 9, 9)\n",
      "('kernel sizes 2=', 8, 40, 9, 9)\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "('conv_idx=', 9)\n",
      "   - New residual block with\n",
      "('      input shape:', (40, 72, 72))\n",
      "('      kernel size:', [9, 9])\n",
      "('short cut kernel sizes=', 40, 9, 9)\n",
      "('kernel sizes 2=', 9, 40, 9, 9)\n",
      "('kernel sizes 2=', 9, 40, 9, 9)\n",
      "        -- model was built.\n",
      "(40L, 40L, 9L, 9L)\n",
      "('feature=288, W size=', (40L, 40L, 9L, 9L))\n",
      "('feature=288, W3 size=', (288L, 40L, 9L, 9L))\n",
      "('conv_idx=', 9)\n",
      "   - New residual block with\n",
      "('      input shape:', (40, 72, 72))\n",
      "('      kernel size:', [9, 9])\n",
      "      - Input channels: 40 ---> num feature maps on out: 288\n",
      "('      - with subsample:', (2, 2))\n",
      "('short cut kernel sizes=', 288, 9, 9)\n",
      "('kernel sizes 1=', 9, 288, 9, 9)\n",
      "('kernel sizes 2=', 9, 288, 9, 9)\n",
      "        -- model was built.\n",
      "(288L, 40L, 9L, 9L)\n",
      "('feature=288, W size=', (288L, 40L, 9L, 9L))\n",
      "('feature=288, W3 size=', (288L, 40L, 9L, 9L))\n",
      "('conv_idx=', 10)\n",
      "   - New residual block with\n",
      "('      input shape:', (288, 36, 36))\n",
      "('      kernel size:', [9, 9])\n",
      "('short cut kernel sizes=', 288, 9, 9)\n",
      "('kernel sizes 2=', 10, 288, 9, 9)\n",
      "('kernel sizes 2=', 10, 288, 9, 9)\n",
      "        -- model was built.\n",
      "(288L, 288L, 9L, 9L)\n",
      "('conv_idx=', 11)\n",
      "   - New residual block with\n",
      "('      input shape:', (288, 36, 36))\n",
      "('      kernel size:', [9, 9])\n",
      "('short cut kernel sizes=', 288, 9, 9)\n",
      "('kernel sizes 2=', 11, 288, 9, 9)\n",
      "('kernel sizes 2=', 11, 288, 9, 9)\n",
      "        -- model was built.\n",
      "(288L, 288L, 9L, 9L)\n",
      "('conv_idx=', 12)\n",
      "   - New residual block with\n",
      "('      input shape:', (288, 36, 36))\n",
      "('      kernel size:', [9, 9])\n",
      "      - Input channels: 288 ---> num feature maps on out: 312\n",
      "('short cut kernel sizes=', 312, 9, 9)\n",
      "('kernel sizes 2=', 12, 312, 9, 9)\n",
      "('kernel sizes 2=', 12, 312, 9, 9)\n",
      "        -- model was built.\n",
      "(312L, 288L, 9L, 9L)\n",
      "('conv_idx=', 12)\n",
      "   - New residual block with\n",
      "('      input shape:', (312, 36, 36))\n",
      "('      kernel size:', [9, 9])\n",
      "      - Input channels: 312 ---> num feature maps on out: 288\n",
      "('      - with subsample:', (2, 2))\n",
      "('short cut kernel sizes=', 288, 9, 9)\n",
      "('kernel sizes 1=', 12, 288, 9, 9)\n",
      "('kernel sizes 2=', 12, 288, 9, 9)\n",
      "        -- model was built.\n",
      "(288L, 312L, 9L, 9L)\n",
      "('conv_idx=', 13)\n",
      "   - New residual block with\n",
      "('      input shape:', (288, 18, 18))\n",
      "('      kernel size:', [9, 9])\n",
      "      - Input channels: 288 ---> num feature maps on out: 312\n",
      "('short cut kernel sizes=', 312, 9, 9)\n",
      "('kernel sizes 2=', 13, 312, 9, 9)\n",
      "('kernel sizes 2=', 13, 312, 9, 9)\n",
      "        -- model was built.\n",
      "(312L, 288L, 9L, 9L)\n",
      "('conv_idx=', 14)\n",
      "   - New residual block with\n",
      "('      input shape:', (312, 18, 18))\n",
      "('      kernel size:', [9, 9])\n",
      "      - Input channels: 312 ---> num feature maps on out: 576\n",
      "('short cut kernel sizes=', 576, 9, 9)\n",
      "('kernel sizes 2=', 14, 576, 9, 9)\n",
      "('kernel sizes 2=', 14, 576, 9, 9)\n",
      "        -- model was built.\n",
      "(576L, 312L, 9L, 9L)\n",
      "('conv_idx=', 14)\n",
      "   - New residual block with\n",
      "('      input shape:', (576, 18, 18))\n",
      "('      kernel size:', [9, 9])\n",
      "      - Input channels: 576 ---> num feature maps on out: 312\n",
      "('      - with subsample:', (2, 2))\n",
      "('short cut kernel sizes=', 312, 9, 9)\n",
      "('kernel sizes 1=', 14, 312, 9, 9)\n",
      "('kernel sizes 2=', 14, 312, 9, 9)\n",
      "        -- model was built.\n",
      "(312L, 576L, 9L, 9L)\n",
      "('conv_idx=', 15)\n",
      "   - New residual block with\n",
      "('      input shape:', (312, 9, 9))\n",
      "('      kernel size:', [9, 9])\n",
      "      - Input channels: 312 ---> num feature maps on out: 576\n",
      "('short cut kernel sizes=', 576, 9, 9)\n",
      "('kernel sizes 2=', 15, 576, 9, 9)\n",
      "('kernel sizes 2=', 15, 576, 9, 9)\n",
      "        -- model was built.\n",
      "(576L, 312L, 9L, 9L)\n",
      "('conv_idx=', 16)\n",
      "   - New residual block with\n",
      "('      input shape:', (576, 9, 9))\n",
      "('      kernel size:', [9, 9])\n",
      "('short cut kernel sizes=', 576, 9, 9)\n",
      "('kernel sizes 2=', 16, 576, 9, 9)\n",
      "('kernel sizes 2=', 16, 576, 9, 9)\n",
      "        -- model was built.\n",
      "(576L, 576L, 9L, 9L)\n",
      "Average pooling, from (9,9) to (1,1)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 1, 148, 148)   0           zeropadding2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 24, 148, 148)  240         zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 24, 148, 148)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 576, 1, 1)     263907808   activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_43 (BatchNorma(None, 576, 1, 1)     1152        sequential_2[1][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 576, 1, 1)     0           batchnormalization_43[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 576)           0           activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             577         flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 1)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 263909777\n",
      "____________________________________________________________________________________________________\n",
      "feature=24, W size= (24L, 1L, 3L, 3L)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.setrecursionlimit(99999)\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import ZeroPadding2D, AveragePooling2D, Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "nb_classes = 1\n",
    "nb_epoch = 20\n",
    "\n",
    "def compute_padding_length(length_before, stride, length_conv):\n",
    "    ''' Assumption: you want the subsampled result has a length of floor(original_length/stride).\n",
    "    '''\n",
    "    N = length_before\n",
    "    F = length_conv\n",
    "    S = stride\n",
    "    if S == F:\n",
    "        return 0\n",
    "    if S == 1:\n",
    "        return (F-1)/2\n",
    "    for P in range(S):\n",
    "        if (N-F+2*P)/S + 1 == N/S:\n",
    "            return P\n",
    "    return 0\n",
    "\n",
    "def design_for_residual_blocks(num_channel_input=1):\n",
    "    ''''''\n",
    "    model = Sequential() # it's a CONTAINER, not MODEL\n",
    "    # set numbers\n",
    "    num_big_blocks = 17\n",
    "#     image_patch_sizes = [[3,3]]*(num_big_blocks+1)\n",
    "    image_patch_sizes = [[6,6],[6,6],[6,6],[6,6],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],\n",
    "                        [9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9],[9,9]]\n",
    "    pool_sizes = [(2,2)]*num_big_blocks\n",
    "#     n_features =      [24,24,24,24,40,40,40, 288,288, 288,512,512, 1024]\n",
    "#     n_features_next = [24,24,24,40,40,40,288,288,288, 512,512,1024,1024]\n",
    "    n_features =      [24,24,24,24,24,40,40,40,40,40, 288,288,312,312,576,576,576]\n",
    "    n_features_next = [24,24,24,24,40,40,40,40,40,288,288,288,288,312,312,576,576]\n",
    "    height_input = 144\n",
    "    width_input = 144\n",
    "        \n",
    "    for conv_idx in range(num_big_blocks):    \n",
    "        n_feat_here = n_features[conv_idx]\n",
    "        n_feat_next = n_features_next[conv_idx]\n",
    "        # residual block 0\n",
    "        model.add(building_residual_block(  (num_channel_input, height_input, width_input),\n",
    "                                                            n_feat_here,n_feat_next,image_patch_sizes,conv_idx,\n",
    "                                                            kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                            kernel2_sizes=image_patch_sizes[conv_idx+1]\n",
    "                                                            ))\n",
    "\n",
    "        # residual block 1 (you can add it as you want (and your resources allow..))\n",
    "        if False:\n",
    "            model.add(building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                                n_feat_here,\n",
    "                                                                kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                                kernel2_sizes=image_patch_sizes[conv_idx+1]\n",
    "                                                                ))\n",
    "        \n",
    "        # the last residual block N-1\n",
    "        # the last one : pad zeros, subsamples, and increase #channels\n",
    "        pad_height = compute_padding_length(height_input, pool_sizes[conv_idx][0], image_patch_sizes[conv_idx][0])\n",
    "        pad_width = compute_padding_length(width_input, pool_sizes[conv_idx][1], image_patch_sizes[conv_idx][1])\n",
    "        model.add(ZeroPadding2D(padding=(pad_height,pad_width))) \n",
    "        height_input += 2*pad_height\n",
    "        width_input += 2*pad_width\n",
    "        n_feat_next = n_features_next[conv_idx]\n",
    "        if n_features[conv_idx] != n_features_next[conv_idx]:\n",
    "            model.add(building_residual_block(  (n_feat_here, height_input, width_input),\n",
    "                                                                n_feat_next,n_feat_next,image_patch_sizes,conv_idx,\n",
    "                                                                kernel_sizes=image_patch_sizes[conv_idx],\n",
    "                                                                kernel2_sizes=image_patch_sizes[conv_idx+1],\n",
    "                                                                is_subsample=True,\n",
    "                                                                subsample=pool_sizes[conv_idx]\n",
    "                                                                ))\n",
    "\n",
    "        height_input, width_input = model.output_shape[2:]\n",
    "        # width_input  = int(width_input/pool_sizes[conv_idx][1])\n",
    "        num_channel_input = n_feat_next\n",
    "\n",
    "    # Add average pooling at the end:\n",
    "    print('Average pooling, from (%d,%d) to (1,1)' % (height_input, width_input))\n",
    "    model.add(AveragePooling2D(pool_size=(height_input, width_input)))\n",
    "    return model\n",
    "\n",
    "def get_residual_model(is_mnist=True, img_channels=1, img_rows=28, img_cols=28):\n",
    "    model = keras.models.Sequential()\n",
    "    first_layer_channel = 24\n",
    "    \n",
    "    W1=sio.loadmat('W1_temp')['W1_temp']\n",
    "    W1=np.asarray(W1, dtype=np.float32)\n",
    "    \n",
    "    if is_mnist: # size to be changed to 32,32\n",
    "        model.add(ZeroPadding2D((2,2), input_shape=(img_channels, img_rows, img_cols))) # resize (28,28)-->(32,32)\n",
    "        # the first conv \n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same'))\n",
    "    else:\n",
    "        model.add(Convolution2D(first_layer_channel, 3, 3, border_mode='same', input_shape=(img_channels, img_rows, img_cols)))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    # [residual-based Conv layers]\n",
    "    residual_blocks = design_for_residual_blocks(num_channel_input=first_layer_channel)\n",
    "#     residual_blocks.layers[2].W.get_value().shape\n",
    "    model.add(residual_blocks)\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    # [Classifier]    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('linear'))\n",
    "    # [END]\n",
    "#     print(model.layers[1].W.get_value().shape)\n",
    "    model.summary()\n",
    "    print('feature=24, W size=',model.layers[1].W.get_value().shape)\n",
    "    return model\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    is_mnist = True\n",
    "    is_cifar10 = not is_mnist\n",
    "\n",
    "    if is_mnist:\n",
    "        import scipy.io as sio\n",
    "        import numpy as np\n",
    "\n",
    "        img_rows, img_cols = 144, 144\n",
    "        img_channels = 1\n",
    "        WB = sio.loadmat('WB_small.mat')['WB_small']\n",
    "        Y_data = sio.loadmat('true.mat')['skt']\n",
    "        Y_data = (Y_data - min(Y_data)) / (max(Y_data) - min(Y_data))\n",
    "        X_data = np.reshape(WB, (100, 1, img_rows, img_cols))\n",
    "        X_train = X_data[0:80];\n",
    "        X_test = X_data[80:100]\n",
    "        Y_train = Y_data[0:80];\n",
    "        Y_test = Y_data[80:100]\n",
    "        print(' == MNIST ==')\n",
    "    else:\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "        img_rows, img_cols = 32, 32\n",
    "        img_channels = 3\n",
    "        print(' == CIFAR10 ==')\n",
    "\n",
    "    import scipy.io as sio\n",
    "    #from keras.utils.theano_utils import sharedX\n",
    "    W1=sio.loadmat('W1_temp')['W1_temp']\n",
    "    W1=np.asarray(W1, dtype=np.float32)\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    # X_train /= 255\n",
    "    # X_test /= 255\n",
    "    # X_train = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "    # X_test = (X_test - np.mean(X_test))/np.std(X_test)\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    model = get_residual_model(is_mnist=is_mnist, img_channels=img_channels, img_rows=img_rows, img_cols=img_cols)\n",
    "    model.layers[1].W.set_value(W1)\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_125 (ZeroPadding2D)(None, 1, 148, 148)   0           zeropadding2d_input_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_350 (Convolution2D)(None, 24, 148, 148)  240         zeropadding2d_125[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_350 (Activation)      (None, 24, 148, 148)  0           convolution2d_350[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "sequential_46 (Sequential)       (None, 288, 1, 1)     22921000    activation_350[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_322 (BatchNorm(None, 288, 1, 1)     576         sequential_46[1][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_365 (Activation)      (None, 288, 1, 1)     0           batchnormalization_322[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)             (None, 288)           0           activation_365[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 1)             289         flatten_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_366 (Activation)      (None, 1)             0           dense_21[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 22922105\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmppc5jzm/561cf3a07c6124dfa8afda3ef055f9de.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmppc5jzm/561cf3a07c6124dfa8afda3ef055f9de.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmp7wcbem/983200c50d11ea510f69ec02b378288e.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmp7wcbem/983200c50d11ea510f69ec02b378288e.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpxebq9u/7e464294e7fd917e4334af0c25d250e9.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpxebq9u/7e464294e7fd917e4334af0c25d250e9.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpgvrhyr/38bd73ab2564abe57c1242ccfd6c5d2c.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpgvrhyr/38bd73ab2564abe57c1242ccfd6c5d2c.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpy1tj8d/322da308b332a5008a0482d46c95a242.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpy1tj8d/322da308b332a5008a0482d46c95a242.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpk8qrum/4703a903e655aaa4b13f4fccf6629f30.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpk8qrum/4703a903e655aaa4b13f4fccf6629f30.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpc0hhtm/887ef546c8e7d58521624ceffe59f12e.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpc0hhtm/887ef546c8e7d58521624ceffe59f12e.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmprikffk/eed5371ff7c41e6b3bfe191c95ec1c94.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmprikffk/eed5371ff7c41e6b3bfe191c95ec1c94.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpxrsh52/d0e106cfdbfc3d82c0fafb510f595de9.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpxrsh52/d0e106cfdbfc3d82c0fafb510f595de9.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpsxoyst/fa6b8ef4ba06703f8d99949368f2fe51.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpsxoyst/fa6b8ef4ba06703f8d99949368f2fe51.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpz6htyl/08b7f1291f0b811b1be2f3697a0bd3fe.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpz6htyl/08b7f1291f0b811b1be2f3697a0bd3fe.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpwakvtb/55215bf745c3a374060f88ab276b7da6.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpwakvtb/55215bf745c3a374060f88ab276b7da6.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpkfl5fg/6208ee0c252a8a3cf10de11185556bfc.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpkfl5fg/6208ee0c252a8a3cf10de11185556bfc.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmp7laqui/87135e870c757f5e37ef15053c900f31.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmp7laqui/87135e870c757f5e37ef15053c900f31.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpl9xbvj/ad23da92838e8a840c29905936290e4d.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpl9xbvj/ad23da92838e8a840c29905936290e4d.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmp0lewqf/b094c66c0cfb57799187ecb52a2102ad.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmp0lewqf/b094c66c0cfb57799187ecb52a2102ad.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpiioogu/26720983e74cb9c6838bd865485085ad.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpiioogu/26720983e74cb9c6838bd865485085ad.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmppl49fx/512f06a20e61135ac5071b8870044604.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmppl49fx/512f06a20e61135ac5071b8870044604.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpew87bo/1f08b8e24ebc71512128db6673c780b9.lib and object C:/Users/p2admin/AppData/Local/Theano/compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_62_Stepping_4_GenuineIntel-2.7.12-64/tmpew87bo/1f08b8e24ebc71512128db6673c780b9.exp\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "('Error allocating 107495424 bytes of device memory (out of memory).', \"you might consider using 'theano.shared(..., borrow=True)'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a70a8b48b5ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1075\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1077\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1078\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# get trainable weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m             \u001b[0mtrainable_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollect_trainable_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m             \u001b[0mtraining_updates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\optimizers.pyc\u001b[0m in \u001b[0;36mget_updates\u001b[1;34m(self, params, constraints, loss)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[0mvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\backend\\theano_backend.pyc\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m    114\u001b[0m     '''Instantiate an all-zeros variable.\n\u001b[0;32m    115\u001b[0m     '''\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\backend\\theano_backend.pyc\u001b[0m in \u001b[0;36mvariable\u001b[1;34m(value, dtype, name)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\theano\\compile\\sharedvalue.pyc\u001b[0m in \u001b[0;36mshared\u001b[1;34m(value, name, strict, allow_downcast, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m                 var = ctor(value, name=name, strict=strict,\n\u001b[1;32m--> 247\u001b[1;33m                            allow_downcast=allow_downcast, **kwargs)\n\u001b[0m\u001b[0;32m    248\u001b[0m                 \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_tag_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\theano\\sandbox\\cuda\\var.pyc\u001b[0m in \u001b[0;36mfloat32_shared_constructor\u001b[1;34m(value, name, strict, allow_downcast, borrow, broadcastable, target)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# type.broadcastable is guaranteed to be a tuple, which this next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# function requires\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mdeviceval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_support_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: ('Error allocating 107495424 bytes of device memory (out of memory).', \"you might consider using 'theano.shared(..., borrow=True)'\")"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, validation_data=(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
